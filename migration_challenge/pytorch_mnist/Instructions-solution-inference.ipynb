{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch MNIST Lift and Shift Exercise\n",
    "\n",
    "For this exercise notebook, use the `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` kernel on SageMaker Studio, or `conda_pytorch_p38` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your new colleague in the data science team (who isn't very familiar with SageMaker) has written a nice notebook to tackle an image classification problem with PyTorch: [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "It works OK with the simple MNIST data set they were working on before, but now they'd like to take advantage of some of the features of SageMaker to tackle bigger and harder challenges.\n",
    "\n",
    "**Can you help refactor the Local Notebook code, to show them how to use SageMaker effectively?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "- [PyTorch MNIST](https://github.com/aws/amazon-sagemaker-examples/tree/main/sagemaker-python-sdk/pytorch_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First, check you can **run the [Local Notebook.ipynb](Local%20Notebook.ipynb) notebook through** - reviewing what steps it takes.\n",
    "\n",
    "**This notebook** sets out a structure you can use to migrate code into, and lists out some of the changes you'll need to make at a high level. You can either work directly in here, or duplicate this notebook so you still have an unchanged copy of the original.\n",
    "\n",
    "Try to work through the sections first with an MVP goal in mind (fitting the model to data in S3 via a SageMaker Training Job, and deploying/using the model through a SageMaker Endpoint). At the end, there are extension exercises to bring in more advanced functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Listing all our imports at the start helps to keep the requirements to run any script/file transparent up-front, and is specified by nearly every style guide including Python's official [PEP 8](https://www.python.org/dev/peps/pep-0008/#imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipycanvas<0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: ipywidgets<8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (7.8.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: pillow>=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipycanvas<0.13) (10.2.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipycanvas<0.13) (1.23.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (8.22.2)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets<8) (1.1.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from widgetsnbextension~=3.6.6->ipywidgets<8) (7.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8) (0.8.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.13.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.25.4)\n",
      "Requirement already satisfied: jupyterlab<4.2,>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.1.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (6.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets<8) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (23.1.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.1.3)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (7.16.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (5.10.3)\n",
      "Requirement already satisfied: overrides in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.20.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.18.1)\n",
      "Requirement already satisfied: websocket-client in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.7.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.27.0)\n",
      "Requirement already satisfied: ipykernel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (6.29.3)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.2.4)\n",
      "Requirement already satisfied: tomli in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.9.24)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.21.1)\n",
      "Requirement already satisfied: requests>=2.31 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.10.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.2.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.2.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (21.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (5.9.8)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.4)\n",
      "Requirement already satisfied: uri-template in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.9.0.20240316)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ipycanvas<0.13\" \"ipywidgets<8\" matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local Notebook Utils:\n",
    "import util\n",
    "\n",
    "# TODO: What else will you need?\n",
    "# Have a look at the documentation: https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html\n",
    "# to see which libraries need to be imported to use sagemaker and the tensorflow estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Let's download the image data from the Repository of Open Data on AWS and sample a subset like we did in the [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "**Check you understand** what data it's going to upload from this notebook, and where it's going to store it in S3, then start the upload running while you work on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-imageclas/mnist_png.tgz to ../../../../../../tmp/mnist/mnist_png.tgz\n",
      "Training files: 60000\n",
      "Testing files:  10000\n",
      "Training files kept: 30000\n",
      "Testing files kept:  5000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "local_dir = \"/tmp/mnist\"\n",
    "training_dir = f\"{local_dir}/training\"\n",
    "testing_dir = f\"{local_dir}/testing\"\n",
    "\n",
    "# Download the MNIST data from the Registry of Open Data on AWS\n",
    "!rm -rf {local_dir}\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the MNIST data, stripping the leading path element; this will leave us with directories\n",
    "# {local_dir}/testing/ and {local_dir/training/\n",
    "!tar zxf {local_dir}/mnist_png.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "\n",
    "# Get the list of files in tne training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "# Reduce the data by keeping every Nth file and dropping the rest of the files.\n",
    "reduction_factor = 2\n",
    "train_files_to_keep = train_files[::reduction_factor]\n",
    "test_files_to_keep = test_files[::reduction_factor]\n",
    "\n",
    "print(f\"Training files kept: {len(train_files_to_keep)}\")\n",
    "print(f\"Testing files kept:  {len(test_files_to_keep)}\")\n",
    "\n",
    "# Delete all the files not to be kept\n",
    "for fname in set(train_files) ^ set(train_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "for fname in set(test_files) ^ set(test_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Execution Role, Session and S3 Bucket\n",
    "\n",
    "Now that we have downloaded and reduced the data in the local directory, we will need to upload it to Amazon S3 to make it available for Amazon Sagemaker training.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region.\n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the **get_execution_role** method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/SageMaker/.xdg/config/sagemaker/config.yaml\n",
      "bucket_name: \n",
      " sagemaker-us-east-1-057716757052\n"
     ]
    }
   ],
   "source": [
    "# TODO: This is where you can setup execution role, session and S3 bucket.\n",
    "# 1. Setup the SageMaker role\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "# 2. Setup the SageMaker session\n",
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "\n",
    "\n",
    "# 3. Setup the SageMaker default bucket\n",
    "bucket_name = sess.default_bucket()\n",
    "print(\"bucket_name: \\n\", bucket_name)\n",
    "\n",
    "\n",
    "# Have a look at the previous examples to find out how to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Amazon S3\n",
    "\n",
    "Next is the part where you need to upload the images to Amazon S3 for Sagemaker training. You can refer to the previous example on how to do it using the [aws s3 sync](https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html) CLI command. The high-level command `aws s3 sync` command synchronizes the contents of the target bucket and source directory. It allows the use of options such as `--delete` that allows to remove objects from the target that are not present in the source and `--exclude` or `--include` options that filter files or objects to exclude or not exclude.\n",
    "\n",
    "> ⏰ Note: Uploading to Amazon S3 typically takes about 2-3 minutes assuming a reduction_factor of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_data_location:  s3://sagemaker-us-east-1-057716757052/sagemaker-mnist\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: This is where you upload the training images using `aws s3 sync`.\n",
    "# Fill in the missing source local directory and the target S3 bucket and folder in the command below.\n",
    "import os\n",
    "\n",
    "bucket_prefix = \"sagemaker-mnist\"\n",
    "s3_data_location = os.path.join ('s3://', bucket_name, bucket_prefix)\n",
    "print(\"s3_data_location: \", s3_data_location)\n",
    "\n",
    "!aws s3 sync --quiet --delete {local_dir} {s3_data_location} --exclude \"*.tgz\" && echo \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE sagemaker-mnist/\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {s3_data_location} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls {s3_data_location}sagemaker-mnist/training --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE training/\n",
      "                           PRE testing/\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-us-east-1-057716757052/sagemaker-mnist/training\n",
    "! aws s3 ls s3://sagemaker-us-east-1-057716757052/sagemaker-mnist/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your data is uploaded by finding your bucket in the [Amazon S3 Console](https://s3.console.aws.amazon.com/s3/home). Do you see the folders of images as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input (\"Channels\") Configuration\n",
    "\n",
    "The draft code has **2 data sets**: One for training, and one for test/validation. (For classification, the folder location of each image is sufficient as a label).\n",
    "\n",
    "In SageMaker terminology, each input data set is a \"channel\" and we can name them however we like... Just make sure you're consistent about what you call each one!\n",
    "\n",
    "For a simple input configuration, a channel spec might just be the S3 URI of the folder. For configuring more advanced options, there's the [s3_input](https://sagemaker.readthedocs.io/en/stable/inputs.html) class in the SageMaker SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  {'train': 's3://sagemaker-us-east-1-057716757052/sagemaker-mnist/training', 'test': 's3://sagemaker-us-east-1-057716757052/sagemaker-mnist/testing'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define your 2 data channels\n",
    "# The data can be found in: \"s3://{bucket_name}/mnist/training\" and \"s3://{bucket_name}/mnist/testing\"\n",
    "# Look at the previous example to see how the inputs were defined\n",
    "train_s3_path = f'{s3_data_location}/training'\n",
    "test_s3_path = f'{s3_data_location}/testing'\n",
    "inputs = { \n",
    "            'train': train_s3_path,\n",
    "            'test' : test_s3_path\n",
    "        }\n",
    "print(\"inputs: \", inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (\"Estimator\") Configuration and Run\n",
    "\n",
    "Instead of loading and fitting this data here in the notebook, we'll be creating a [PyTorch Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#pytorch-estimator) through the SageMaker SDK, to run the code on a separate container that can be scaled as required.\n",
    "\n",
    "The [\"Using PyTorch with the SageMaker Python SDK\"](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html) docs give a good overview of this process. You should run your estimator in **Python 3**.\n",
    "\n",
    "**Use the [src/main.py](src/main.py) file** as your entry point to port code into - which has already been created for you with some basic hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive script 로 훈련 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the actual training on SageMaker TrainingJob, it can be good to run it locally first using the code below. If there is any error, you can fix them first before running using SageMaker TrainingJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_model_dir:  /tmp/mnist/model\n"
     ]
    }
   ],
   "source": [
    "save_model_dir = f\"{local_dir}/model\"\n",
    "print(\"save_model_dir: \", save_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Naive mode is set\n",
      "## args: \n",
      " Namespace(train_dir='/tmp/mnist/training', test_dir='/tmp/mnist/testing', model_dir='/tmp/mnist/model', output_data_dir='data/local-output', batch_size=128, test_batch_size=1000, epochs=1)\n",
      "args.training data:  /tmp/mnist/training\n",
      "args.test data:  /tmp/mnist/testing\n",
      "##: Starting X, y dataset creation\n",
      "Loading label 0...1...2...3...4...5...6...7...8...9...\n",
      "Shuffling trainset...\n",
      "Shuffling testset...\n",
      "Done!\n",
      "##: Starting preprocess\n",
      "x_train shape: (30000, 1, 28, 28)\n",
      "input_shape: (1, 28, 28)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "n_labels: 10\n",
      "y_train shape: (30000, 10)\n",
      "##: trainloader is successfully loaded \n",
      "##: testloader is successfully loaded \n",
      "## Start training \n",
      "epoch: 1\n",
      "train_loss: 0.000796\n",
      "Evaluating model\n",
      "## Start testing \n",
      "val_loss: 0.0338\n",
      "val_acc: 0.9434\n",
      "Saving model at /tmp/mnist/model/model.pth\n",
      "## model is saved at /tmp/mnist/model/model.pth\n"
     ]
    }
   ],
   "source": [
    "!python3 src/main-solution.py \\\n",
    "    --train_dir {training_dir} \\\n",
    "    --test_dir {testing_dir} \\\n",
    "    --output-data-dir data/local-output \\\n",
    "    --model-dir {save_model_dir} \\\n",
    "    --epochs=1 --batch-size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready to try your script in a Sagemaker training job, you can call `estimator.fit()` as we did in previous exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬 모드 혹은 클라우드 모드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cloud mode is set with ml.g5.2xlarge and 1 of instance_count\n"
     ]
    }
   ],
   "source": [
    "# USE_LOCAL_MODE = True\n",
    "USE_LOCAL_MODE = False\n",
    "\n",
    "import torch\n",
    "\n",
    "if USE_LOCAL_MODE:\n",
    "    instance_type = 'local_gpu' if torch.cuda.is_available() else 'local'\n",
    "    instance_count = 1\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    print(\"## Local mode is set\")\n",
    "\n",
    "else:\n",
    "    instance_type = 'ml.g5.2xlarge'\n",
    "    instance_count = 1\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    print(f\"## Cloud mode is set with {instance_type} and {instance_count} of instance_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: \n",
      " 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "image_uri = '763104351884.dkr.ecr.{}.amazonaws.com/pytorch-training:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker'.format(region)\n",
    "print(\"image_uri: \\n\", image_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bUseTrainWarmPool = True ## training image 다운받지 않음, 속도 빨라진다\n",
    "if bUseTrainWarmPool: nKeepAliveSeconds = 3600 ## 최대 1시간 동안!!, service quota에서 warmpool을 위한 request 필요\n",
    "else: nKeepAliveSeconds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your PyTorch estimator\n",
    "\n",
    "# Note the PyTorch class inherits from some cross-framework base classes with additional\n",
    "# constructor options:\n",
    "# https://sagemaker.readthedocs.io/en/stable/estimators.html\n",
    "# https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#create-an-estimator\n",
    "\n",
    "# We are using PyTorch 1.8 and python 3\n",
    "# You can reuse the metrics definition from the previous example\n",
    "# (Optional) Look at the Pytorch script and try to pass new hyperparameters\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# define Training Job Name \n",
    "import time\n",
    "job_name = f'sagemaker-101-pytorch-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "\n",
    "\n",
    "estimator = PyTorch(entry_point = 'main-solution.py',\n",
    "                    source_dir = 'src',\n",
    "                    image_uri = image_uri,\n",
    "                    instance_type= instance_type,\n",
    "                    instance_count=1,\n",
    "                    base_job_name= job_name,    \n",
    "                    role = role,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    framework_version='1.8.0',\n",
    "                    py_version='py3',\n",
    "                    keep_alive_period_in_seconds=nKeepAliveSeconds,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734\n"
     ]
    }
   ],
   "source": [
    "# TODO: Call estimator.fit\n",
    "estimator.fit(inputs, wait=False)\n",
    "train_job_name = estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker training job, cloudwatch log 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b> [PyTorch DeepSpeed Training] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734\">Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b> [PyTorch DeepSpeed Training] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/TrainingJobs;prefix=sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def make_console_link(region, train_job_name, train_task='[Training]'):\n",
    "    train_job_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/jobs/{train_job_name}\">Training Job</a></b>'   \n",
    "    cloudwatch_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={region}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={train_job_name};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>'\n",
    "    return train_job_link, cloudwatch_link  \n",
    "        \n",
    "if ~USE_LOCAL_MODE:\n",
    "    train_job_link, cloudwatch_link = make_console_link(region, train_job_name, '[PyTorch DeepSpeed Training]')\n",
    "    display(HTML(train_job_link))\n",
    "    display(HTML(cloudwatch_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 잡의 로그 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-19 14:26:35 Starting - Starting the training job\n",
      "2024-06-19 14:26:35 Pending - Training job waiting for capacity.....................\n",
      "2024-06-19 14:29:45 Downloading - Downloading input data..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-06-19 14:30:11,215 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-06-19 14:30:11,236 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-19 14:30:11,247 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-06-19 14:30:11,249 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-06-19 14:30:11,503 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-19 14:30:11,536 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-19 14:30:11,571 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-19 14:30:11,583 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main-solution\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main-solution.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=main-solution.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=main-solution\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/source/sourcedir.tar.gz\",\"module_name\":\"main-solution\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main-solution.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/flash_attn-0.1-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/einops-0.6.0-py3.8.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 main-solution.py\n",
      "2024-06-19 14:30:13,833 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "## SageMaker Local or Cloud mode is set\n",
      "## args: \n",
      " Namespace(batch_size=64, epochs=1, model_dir='/opt/ml/model', output_data_dir='/opt/ml/output/data', test_batch_size=1000, test_dir='/opt/ml/input/data/test', train_dir='/opt/ml/input/data/train')\n",
      "args.training data:  /opt/ml/input/data/train\n",
      "args.test data:  /opt/ml/input/data/test\n",
      "##: Starting X, y dataset creation\n",
      "Loading label 0...\n",
      "1...\n",
      "2...\n",
      "3...\n",
      "4...\n",
      "5...\n",
      "6...\n",
      "7...\n",
      "8...\n",
      "9...\n",
      "Shuffling trainset...\n",
      "Shuffling testset...\n",
      "Done!\n",
      "##: Starting preprocess\n",
      "x_train shape: (30000, 1, 28, 28)\n",
      "input_shape: (1, 28, 28)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "n_labels: 10\n",
      "y_train shape: (30000, 10)\n",
      "##: trainloader is successfully loaded\n",
      "##: testloader is successfully loaded \n",
      "## Start training\n",
      "\n",
      "2024-06-19 14:30:10 Training - Training image download completed. Training in progress.[2024-06-19 14:30:21.842 algo-1:51 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2024-06-19 14:30:22.265 algo-1:51 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2024-06-19 14:30:22.266 algo-1:51 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2024-06-19 14:30:22.267 algo-1:51 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2024-06-19 14:30:22.267 algo-1:51 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2024-06-19 14:30:22.267 algo-1:51 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "epoch: 1\n",
      "train_loss: 0.001302\n",
      "Evaluating model\n",
      "## Start testing\n",
      "val_loss: 0.0216\n",
      "val_acc: 0.9610\n",
      "Saving model at /opt/ml/model/model.pth\n",
      "## model is saved at /opt/ml/model/model.pth\n",
      "2024-06-19 14:30:30,809 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-06-19 14:30:30,809 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-06-19 14:30:30,809 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-06-19 14:30:51 Uploading - Uploading generated training model\n",
      "2024-06-19 14:30:51 Completed - Resource retained for reuse\n",
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Use Your Model (Real-Time Inference)\n",
    "\n",
    "If your training job has completed; and saved the model in the correct PyTorch model format; it should now be pretty simple to deploy the model to a real-time endpoint.\n",
    "\n",
    "You can achieve this with the [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/output/model.tar.gz), script artifact (s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TODO: Deploy a real-time endpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictor \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mdeploy(initial_instance_count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, instance_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mml.m4.xlarge\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1680\u001b[0m, in \u001b[0;36mEstimatorBase.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, serverless_inference_config, async_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m model\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m model_name\n\u001b[1;32m   1676\u001b[0m tags \u001b[39m=\u001b[39m update_inference_tags_with_jumpstart_training_tags(\n\u001b[1;32m   1677\u001b[0m     inference_tags\u001b[39m=\u001b[39mformat_tags(tags), training_tags\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtags\n\u001b[1;32m   1678\u001b[0m )\n\u001b[0;32m-> 1680\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mdeploy(\n\u001b[1;32m   1681\u001b[0m     instance_type\u001b[39m=\u001b[39;49minstance_type,\n\u001b[1;32m   1682\u001b[0m     initial_instance_count\u001b[39m=\u001b[39;49minitial_instance_count,\n\u001b[1;32m   1683\u001b[0m     serializer\u001b[39m=\u001b[39;49mserializer,\n\u001b[1;32m   1684\u001b[0m     deserializer\u001b[39m=\u001b[39;49mdeserializer,\n\u001b[1;32m   1685\u001b[0m     accelerator_type\u001b[39m=\u001b[39;49maccelerator_type,\n\u001b[1;32m   1686\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49mendpoint_name,\n\u001b[1;32m   1687\u001b[0m     tags\u001b[39m=\u001b[39;49mtags \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags,\n\u001b[1;32m   1688\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1689\u001b[0m     kms_key\u001b[39m=\u001b[39;49mkms_key,\n\u001b[1;32m   1690\u001b[0m     data_capture_config\u001b[39m=\u001b[39;49mdata_capture_config,\n\u001b[1;32m   1691\u001b[0m     serverless_inference_config\u001b[39m=\u001b[39;49mserverless_inference_config,\n\u001b[1;32m   1692\u001b[0m     async_inference_config\u001b[39m=\u001b[39;49masync_inference_config,\n\u001b[1;32m   1693\u001b[0m     explainer_config\u001b[39m=\u001b[39;49mexplainer_config,\n\u001b[1;32m   1694\u001b[0m     volume_size\u001b[39m=\u001b[39;49mvolume_size,\n\u001b[1;32m   1695\u001b[0m     model_data_download_timeout\u001b[39m=\u001b[39;49mmodel_data_download_timeout,\n\u001b[1;32m   1696\u001b[0m     container_startup_health_check_timeout\u001b[39m=\u001b[39;49mcontainer_startup_health_check_timeout,\n\u001b[1;32m   1697\u001b[0m     inference_recommendation_id\u001b[39m=\u001b[39;49minference_recommendation_id,\n\u001b[1;32m   1698\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/model.py:1685\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, routing_config, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[39mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1683\u001b[0m     explainer_config_dict \u001b[39m=\u001b[39m explainer_config\u001b[39m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1685\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mendpoint_from_production_variants(\n\u001b[1;32m   1686\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m   1687\u001b[0m     production_variants\u001b[39m=\u001b[39;49m[production_variant],\n\u001b[1;32m   1688\u001b[0m     tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m   1689\u001b[0m     kms_key\u001b[39m=\u001b[39;49mkms_key,\n\u001b[1;32m   1690\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1691\u001b[0m     data_capture_config_dict\u001b[39m=\u001b[39;49mdata_capture_config_dict,\n\u001b[1;32m   1692\u001b[0m     explainer_config_dict\u001b[39m=\u001b[39;49mexplainer_config_dict,\n\u001b[1;32m   1693\u001b[0m     async_inference_config_dict\u001b[39m=\u001b[39;49masync_inference_config_dict,\n\u001b[1;32m   1694\u001b[0m     live_logging\u001b[39m=\u001b[39;49mendpoint_logging,\n\u001b[1;32m   1695\u001b[0m )\n\u001b[1;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1698\u001b[0m     predictor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor_cls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:5711\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n\u001b[1;32m   5708\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCreating endpoint-config with name \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, name)\n\u001b[1;32m   5709\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mcreate_endpoint_config(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_options)\n\u001b[0;32m-> 5711\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_endpoint(\n\u001b[1;32m   5712\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   5713\u001b[0m     config_name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   5714\u001b[0m     tags\u001b[39m=\u001b[39;49mendpoint_tags,\n\u001b[1;32m   5715\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   5716\u001b[0m     live_logging\u001b[39m=\u001b[39;49mlive_logging,\n\u001b[1;32m   5717\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:4569\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n\u001b[1;32m   4566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint_arn \u001b[39m=\u001b[39m res[\u001b[39m\"\u001b[39m\u001b[39mEndpointArn\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   4568\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 4569\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_for_endpoint(endpoint_name, live_logging\u001b[39m=\u001b[39;49mlive_logging)\n\u001b[1;32m   4570\u001b[0m \u001b[39mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:5354\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n\u001b[1;32m   5348\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCapacityError\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(reason):\n\u001b[1;32m   5349\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mCapacityError(\n\u001b[1;32m   5350\u001b[0m             message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   5351\u001b[0m             allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mInService\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   5352\u001b[0m             actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   5353\u001b[0m         )\n\u001b[0;32m-> 5354\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   5355\u001b[0m         message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   5356\u001b[0m         allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mInService\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   5357\u001b[0m         actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   5358\u001b[0m     )\n\u001b[1;32m   5359\u001b[0m \u001b[39mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-31-18-636: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy a real-time endpoint\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 추론 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 아티펙트 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_s3_path = estimator.model_data\n",
    "print(\"model_s3_path: \\n\", model_s3_path)\n",
    "\n",
    "local_model_dir = 'local_model'\n",
    "os.makedirs(local_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-057716757052/sagemaker-101-pytorch-2024-06-19-14-26--2024-06-19-14-26-33-734/output/model.tar.gz to local_model/model.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_s3_path} {local_model_dir}\n",
    "\n",
    "model_s3_path=$1\n",
    "local_model_dir=$2\n",
    "# 모델을 S3에서 로컬로 다운로드\n",
    "aws s3 cp $model_s3_path $local_model_dir\n",
    "\n",
    "# 모델 다운로드 폴더로 이동\n",
    "cd $local_model_dir\n",
    "\n",
    "# 압축 해제\n",
    "tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)\n",
    "\n",
    "local_model_dir = 'local_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    '''\n",
    "    Load a model\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.jit.load(os.path.join(model_dir, 'model.pth'))\n",
    "    model = model.to(device)\n",
    "    print(\"Model is successfully loaded\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = model_fn(local_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_fn 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data:  (784,)\n",
      "payload: \n",
      " {\"input\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24705882370471954, 1.0, 0.9921568632125854, 0.9098039269447327, 0.4274509847164154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5647059082984924, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.6117647290229797, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0235294122248888, 0.6274510025978088, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.7450980544090271, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14509804546833038, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.6039215922355652, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14509804546833038, 0.9882352948188782, 0.9921568632125854, 0.13725490868091583, 0.08235294371843338, 0.8039215803146362, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14509804546833038, 0.9882352948188782, 0.9921568632125854, 0.13725490868091583, 0.0, 0.40784314274787903, 0.8274509906768799, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.6117647290229797, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04313725605607033, 0.6039215922355652, 0.2823529541492462, 0.03921568766236305, 0.0, 0.0, 0.12156862765550613, 0.8078431487083435, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.5411764979362488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8274509906768799, 0.9882352948188782, 0.9921568632125854, 0.7019608020782471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47058823704719543, 0.9921568632125854, 1.0, 0.8274509906768799, 0.12156862765550613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14509804546833038, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.27843138575553894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14509804546833038, 0.9882352948188782, 0.9921568632125854, 0.9450980424880981, 0.239215686917305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16470588743686676, 0.24313725531101227, 0.5647059082984924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47058823704719543, 0.9882352948188782, 0.9921568632125854, 0.7019608020782471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8549019694328308, 0.9921568632125854, 0.9921568632125854, 0.7490196228027344, 0.30588236451148987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125490203499794, 0.8313725590705872, 0.9921568632125854, 1.0, 0.7058823704719543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3686274588108063, 0.9686274528503418, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9490196108818054, 0.8509804010391235, 0.5254902243614197, 0.0, 0.0, 0.0, 0.0, 0.125490203499794, 0.8117647171020508, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.7843137383460999, 0.24705882370471954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4274509847164154, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.7137255072593689, 0.7098039388656616, 0.30588236451148987, 0.14509804546833038, 0.8313725590705872, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.8666666746139526, 0.062745101749897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4274509847164154, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.6627451181411743, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9058823585510254, 0.18039216101169586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4313725531101227, 0.9921568632125854, 0.9921568632125854, 0.9921568632125854, 0.4274509847164154, 0.5882353186607361, 0.9921568632125854, 0.9921568632125854, 1.0, 0.9921568632125854, 0.9921568632125854, 0.9921568632125854, 1.0, 0.9921568632125854, 0.9921568632125854, 0.9921568632125854, 1.0, 0.9921568632125854, 0.6039215922355652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30588236451148987, 0.9490196108818054, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.7058823704719543, 0.5411764979362488, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24313725531101227, 0.7882353067398071, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9882352948188782, 0.9921568632125854, 0.8627451062202454, 0.7647058963775635, 0.27843138575553894, 0.2823529541492462, 0.27843138575553894, 0.27843138575553894, 0.27843138575553894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30588236451148987, 0.42352941632270813, 0.9882352948188782, 0.8235294222831726, 0.42352941632270813, 0.42352941632270813, 0.42352941632270813, 0.05882352963089943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"resolution\": [28, 28]}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "def create_payload(label, testing_dir):\n",
    "    filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "\n",
    "    # Load the image:\n",
    "    img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "    # normalize\n",
    "    input_data = np.asarray(img).astype(np.float32) / 255\n",
    "    input_data = np.expand_dims(input_data, [0, 1])  # Add batch & leading channel dim\n",
    "    input_data = input_data.flatten().tolist()\n",
    "    print(\"input_data: \", np.shape(input_data))\n",
    "\n",
    "    payload = {\n",
    "        'input': input_data, # input_data\n",
    "        'resolution' : [28, 28]\n",
    "    }\n",
    "\n",
    "    return json.dumps(payload)\n",
    "\n",
    "payload = create_payload(label=2, testing_dir=testing_dir)\n",
    "print(\"payload: \\n\", payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape:  torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def input_fn(input_data, content_type):\n",
    "    if content_type == 'application/json':\n",
    "        data = json.loads(input_data)[\"input\"]\n",
    "        resolution = json.loads(input_data)[\"resolution\"]\n",
    "        \n",
    "        data = np.array(data).reshape(resolution)\n",
    "        data = np.squeeze(data).astype(np.float32) / 255\n",
    "        data = torch.tensor(data).unsqueeze(0).unsqueeze(0)    \n",
    "        print(\"np.shape: \", np.shape(data))\n",
    "\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_data = input_fn(input_data=payload, content_type='application/json')\n",
    "\n",
    "\n",
    "# # Load the image:\n",
    "# img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "# input_data = np.asarray(img).astype(np.float32) / 255\n",
    "# input_data_shape = np.shape(input_data)\n",
    "# input_data = input_data.flatten()\n",
    "# np.shape(input_data)\n",
    "# input_data = input_data.reshape(input_data_shape)\n",
    "# np.shape(input_data)\n",
    "# input_data = torch.tensor(input_data).unsqueeze(0).unsqueeze(0)    \n",
    "    \n",
    "\n",
    "# normalize\n",
    "# input_data = np.asarray(img).astype(np.float32) / 255\n",
    "\n",
    "\n",
    "# input_fn2(input_data, request_content_type=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "\n",
    "# def input_fn(input_data, content_type=None):\n",
    "#     if content_type == 'application/json':\n",
    "#         input_data = json.loads(request_body)\n",
    "        \n",
    "#     return input_data\n",
    "\n",
    "# label =2\n",
    "# filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "\n",
    "# # Load the image:\n",
    "# img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "# # normalize\n",
    "# input_data = np.asarray(img).astype(np.float32) / 255\n",
    "# input_data = np.expand_dims(input_data, [0, 1])  # Add batch & leading channel dim\n",
    "\n",
    "# # payload = {\n",
    "# #     'input_data': [1,2,3] # input_data\n",
    "# # }\n",
    "\n",
    "\n",
    "# # JSON 형식으로 입력 데이터 직렬화\n",
    "# # serialized_input_data = json.dumps(payload)\n",
    "# input_data = input_fn(input_data=input_data, content_type=None)\n",
    "# # input_data = input_fn(input_data=serialized_input_data, content_type=None)\n",
    "\n",
    "# print(\"input_data shape: \", np.shape(input_data))\n",
    "# input_data = torch.Tensor(input_data)\n",
    "# print(\"type: \", type(input_data))\n",
    "# # input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_fn 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([1, 1, 28, 28])\n",
      "Result confidences: tensor([[0.0832, 0.1261, 0.0860, 0.0936, 0.0987, 0.1245, 0.0859, 0.1089, 0.0866,\n",
      "         0.1066]], device='cuda:0')\n",
      "Max confidence index: 1\n"
     ]
    }
   ],
   "source": [
    "def predict_fn(input_data, model):\n",
    "    '''\n",
    "    모델의 추론 함수\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_data = input_data.to(device)\n",
    "    print(\"shape: \", np.shape(input_data))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = model(input_data)\n",
    "    print(f\"Result confidences: {result}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "result = predict_fn(input_data=input_data, model=model)\n",
    "max_index = torch.argmax(result).item()    \n",
    "print(\"Max confidence index:\", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_fn(prediction, content_type):\n",
    "    return json.dumps(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the architecture from the example notebook, we set up the model to accept **batches** of **28x28** image tensors with **normalized 0-1 pixel values** and a **single color channel dimension**.\n",
    "\n",
    "Assuming you haven't [added any custom inference pre-processing](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model) to the script (for example to accept encoded JPEGs/PNGs, or arbitrary image shapes), we'll need to replicate that same format when we use our endpoint.\n",
    "\n",
    "You can use the final \"Explore Results\" section of the local notebook as a guide. First, using the interactive widget:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 로컬 추론 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Choose an image:\n",
    "\n",
    "def predict_mnist(label, local_model_dir, testing_dir ):\n",
    "\n",
    "    # Handle input\n",
    "    # Load the image:\n",
    "    filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "    img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "    # normalize\n",
    "    input_data = np.squeeze(np.asarray(img)).astype(np.float32) / 255\n",
    "    input_data = torch.tensor(np.expand_dims(input_data, [0, 1]))  # Add batch & leading channel dim\n",
    "    \n",
    "    # call input_fn as dummy\n",
    "    # input_data = input_fn(input_data=input_data, content_type=None)\n",
    "\n",
    "    print(\"input_data shape: \", np.shape(input_data))\n",
    "\n",
    "    # load model\n",
    "    model = model_fn(local_model_dir)\n",
    "\n",
    "    # predict label\n",
    "    result = predict_fn(input_data=input_data, model=model)\n",
    "    max_index = torch.argmax(result).item()    \n",
    "    print(\"Max confidence index:\", max_index)\n",
    "    \n",
    "    # input_data = np.squeeze(np.asarray(img)).astype(np.float32) / 255\n",
    "    # input_data = torch.tensor(np.expand_dims(input_data, [0, 1]))  # Add batch & leading channel dim\n",
    "\n",
    "    # # Send to the model:\n",
    "    # with torch.no_grad():\n",
    "    #     result = model(input_data)\n",
    "    # print(f\"Result confidences: {result}\")\n",
    "\n",
    "    # Plot the result:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    fig = plt.subplot(1, 1, 1)\n",
    "    ax = plt.imshow(img, cmap=\"gray\")\n",
    "    fig.set_title(f\"Predicted Number {max_index}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data shape:  torch.Size([1, 1, 28, 28])\n",
      "Model is successfully loaded\n",
      "shape:  torch.Size([1, 1, 28, 28])\n",
      "Result confidences: tensor([[2.5125e-05, 2.6190e-05, 1.2528e-05, 9.5807e-01, 2.0152e-07, 4.1812e-02,\n",
      "         9.5869e-07, 1.2248e-06, 1.6725e-05, 3.0621e-05]], device='cuda:0')\n",
      "Max confidence index: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict_mnist(label=3, local_model_dir=local_model_dir, testing_dir=testing_dir )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data shape:  torch.Size([1, 1, 28, 28])\n",
      "Model is successfully loaded\n",
      "shape:  torch.Size([1, 1, 28, 28])\n",
      "Result confidences: tensor([[2.7935e-06, 3.8688e-07, 9.7736e-07, 6.1744e-04, 1.4950e-04, 5.7962e-04,\n",
      "         2.3083e-08, 6.4018e-03, 4.6521e-05, 9.9220e-01]], device='cuda:0')\n",
      "Max confidence index: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_mnist(label=9, local_model_dir=local_model_dir, testing_dir=testing_dir )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import model_fn , input_fn, predict_fn\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_model_path:  local_model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "local_model_path = os.path.join(local_model_dir, 'model.tar.gz')\n",
    "print(\"local_model_path: \", local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "instance_type = 'local_gpu' if torch.cuda.is_available() else 'local'\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Repacking model artifact (local_model/model.tar.gz), script artifact (src), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-057716757052/pytorch-inference-2024-06-18-15-27-07-974/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-06-18-15-27-08-757\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating endpoint-config with name local-endpoint-mnist-1718724427\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating endpoint with name local-endpoint-mnist-1718724427\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.image:serving\n",
      "INFO:sagemaker.local.image:creating hosting dir in /tmp/tmpy952j82r\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-7fodr:\n",
      "    command: serve\n",
      "    container_name: xqkzxa2pae-algo-1-7fodr\n",
      "    deploy:\n",
      "      resources:\n",
      "        reservations:\n",
      "          devices:\n",
      "          - capabilities:\n",
      "            - gpu\n",
      "            count: all\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.0.1-gpu-py310\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-7fodr\n",
      "    ports:\n",
      "    - 8080:8080\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpqd5lb0gs:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpy952j82r/docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 5\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5b6e3fcdc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5b6e3fccd0>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5b6e3fd030>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "INFO:sagemaker.local.entities:Container still not up, got: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to xqkzxa2pae-algo-1-7fodr\n",
      "xqkzxa2pae-algo-1-7fodr  | ['torchserve', '--start', '--model-store', '/.sagemaker/ts/models', '--ts-config', '/etc/sagemaker-ts.properties', '--log-config', '/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/etc/log4j2.xml', '--models', 'model=/opt/ml/model']\n",
      "xqkzxa2pae-algo-1-7fodr  | Warning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport\n",
      "xqkzxa2pae-algo-1-7fodr  | WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,501 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,504 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,574 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,721 [INFO ] main org.pytorch.serve.ModelServer - \n",
      "xqkzxa2pae-algo-1-7fodr  | Torchserve version: 0.8.2\n",
      "xqkzxa2pae-algo-1-7fodr  | TS Home: /opt/conda/lib/python3.10/site-packages\n",
      "xqkzxa2pae-algo-1-7fodr  | Current directory: /\n",
      "xqkzxa2pae-algo-1-7fodr  | Temp directory: /home/model-server/tmp\n",
      "xqkzxa2pae-algo-1-7fodr  | Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\n",
      "xqkzxa2pae-algo-1-7fodr  | Number of GPUs: 4\n",
      "xqkzxa2pae-algo-1-7fodr  | Number of CPUs: 32\n",
      "xqkzxa2pae-algo-1-7fodr  | Max heap size: 30688 M\n",
      "xqkzxa2pae-algo-1-7fodr  | Python executable: /opt/conda/bin/python3.10\n",
      "xqkzxa2pae-algo-1-7fodr  | Config file: /etc/sagemaker-ts.properties\n",
      "xqkzxa2pae-algo-1-7fodr  | Inference address: http://0.0.0.0:8080\n",
      "xqkzxa2pae-algo-1-7fodr  | Management address: http://0.0.0.0:8080\n",
      "xqkzxa2pae-algo-1-7fodr  | Metrics address: http://127.0.0.1:8082\n",
      "xqkzxa2pae-algo-1-7fodr  | Model Store: /.sagemaker/ts/models\n",
      "xqkzxa2pae-algo-1-7fodr  | Initial Models: model=/opt/ml/model\n",
      "xqkzxa2pae-algo-1-7fodr  | Log dir: /logs\n",
      "xqkzxa2pae-algo-1-7fodr  | Metrics dir: /logs\n",
      "xqkzxa2pae-algo-1-7fodr  | Netty threads: 0\n",
      "xqkzxa2pae-algo-1-7fodr  | Netty client threads: 0\n",
      "xqkzxa2pae-algo-1-7fodr  | Default workers per model: 1\n",
      "xqkzxa2pae-algo-1-7fodr  | Blacklist Regex: N/A\n",
      "xqkzxa2pae-algo-1-7fodr  | Maximum Response Size: 6553500\n",
      "xqkzxa2pae-algo-1-7fodr  | Maximum Request Size: 6553500\n",
      "xqkzxa2pae-algo-1-7fodr  | Limit Maximum Image Pixels: true\n",
      "xqkzxa2pae-algo-1-7fodr  | Prefer direct buffer: false\n",
      "xqkzxa2pae-algo-1-7fodr  | Allowed Urls: [file://.*|http(s)?://.*]\n",
      "xqkzxa2pae-algo-1-7fodr  | Custom python dependency for model allowed: false\n",
      "xqkzxa2pae-algo-1-7fodr  | Enable metrics API: true\n",
      "xqkzxa2pae-algo-1-7fodr  | Metrics mode: log\n",
      "xqkzxa2pae-algo-1-7fodr  | Disable system metrics: true\n",
      "xqkzxa2pae-algo-1-7fodr  | Workflow Store: /.sagemaker/ts/models\n",
      "xqkzxa2pae-algo-1-7fodr  | Model config: N/A\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,728 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,754 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,758 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,758 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,761 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,771 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,839 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,839 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:12,840 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\n",
      "xqkzxa2pae-algo-1-7fodr  | Model server started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,276 [INFO ] pool-2-thread-2 ACCESS_LOG - /172.19.0.1:56232 \"GET /ping HTTP/1.1\" 200 12\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,277 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:fc5fecc824a6,timestamp:1718724434\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,427 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=103\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,429 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,438 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,439 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]103\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,439 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,440 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,442 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,448 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,451 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1718724434451\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,474 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,693 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 220\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,694 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:1927.0|#WorkerName:W-9000-model_1.0,Level:Host|#hostname:fc5fecc824a6,timestamp:1718724434\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:27:14,695 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:24.0|#Level:Host|#hostname:fc5fecc824a6,timestamp:1718724434\n",
      "!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "endpoint_name = \"local-endpoint-mnist-{}\".format(int(time.time()))\n",
    "\n",
    "local_pytorch_model = PyTorchModel(model_data=local_model_path,\n",
    "                                   role=role,\n",
    "                                   entry_point='inference.py',\n",
    "                                   source_dir = 'src',\n",
    "                                   framework_version='2.0.1',\n",
    "                                   py_version='py310',\n",
    "                                   model_server_workers=1,\n",
    "                                  )\n",
    "\n",
    "local_predictor = local_pytorch_model.deploy(\n",
    "                           instance_type=instance_type, \n",
    "                           initial_instance_count=1, \n",
    "                           endpoint_name=endpoint_name,\n",
    "                           wait=True,\n",
    "                           log = False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드포인트 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_data:  (1, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "# local_predictor.serializer = JSONSerializer('application/json')\n",
    "\n",
    "\n",
    "filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "input_data = np.squeeze(np.asarray(img)).astype(np.float32) / 255\n",
    "# input_data = torch.tensor(np.expand_dims(input_data, [0, 1]))  # Add batch & leading channel dim\n",
    "input_data = np.expand_dims(input_data, [0, 1])  # Add batch & leading channel dim\n",
    "print(\"shape of input_data: \", np.shape(input_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,973 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,975 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1718724908975\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,979 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Model is successfully loaded\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,979 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,980 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.19.0.1:55862 \"POST /invocations HTTP/1.1\" 500 11\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,981 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:fc5fecc824a6,1718724908,90717991-88f6-4705-acf1-d9fc7616adfe, pattern=[METRICS]\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,982 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,982 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4940.103|#model_name:model,model_version:default|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,983 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:156.134|#model_name:model,model_version:default|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,983 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,984 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,984 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:6.0|#Level:Host|#hostname:fc5fecc824a6,timestamp:1718724908\n",
      "xqkzxa2pae-algo-1-7fodr  | 2024-06-18T15:35:08,984 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:0.6|#ModelName:model,Level:Model|#hostname:fc5fecc824a6,requestID:90717991-88f6-4705-acf1-d9fc7616adfe,timestamp:1718724908\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please set the param allow_pickle=True                         to deserialize pickle objects in NumpyDeserializer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_deserializers.py:231\u001b[0m, in \u001b[0;36mNumpyDeserializer.deserialize\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mload(io\u001b[39m.\u001b[39;49mBytesIO(stream\u001b[39m.\u001b[39;49mread()), allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle)\n\u001b[1;32m    232\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/numpy/lib/npyio.py:418\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 418\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot load file containing pickled data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mwhen allow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m local_predictor\u001b[39m.\u001b[39;49mpredict(input_data)\n\u001b[1;32m      2\u001b[0m result\n\u001b[1;32m      3\u001b[0m \u001b[39m# local_predictor.predict(json.dumps(payload))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:213\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[39m\"\u001b[39m\u001b[39mInferenceComponentName\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m inference_component_name\n\u001b[1;32m    212\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39msagemaker_runtime_client\u001b[39m.\u001b[39minvoke_endpoint(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrequest_args)\n\u001b[0;32m--> 213\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:219\u001b[0m, in \u001b[0;36mPredictor._handle_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    217\u001b[0m response_body \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mBody\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    218\u001b[0m content_type \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContentType\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapplication/octet-stream\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeserializer\u001b[39m.\u001b[39;49mdeserialize(response_body, content_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_deserializers.py:233\u001b[0m, in \u001b[0;36mNumpyDeserializer.deserialize\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mload(io\u001b[39m.\u001b[39mBytesIO(stream\u001b[39m.\u001b[39mread()), allow_pickle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_pickle)\n\u001b[1;32m    232\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[0;32m--> 233\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease set the param allow_pickle=True \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m            to deserialize pickle objects in NumpyDeserializer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\u001b[39m.\u001b[39mwith_traceback(ve\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m content_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/x-npz\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    238\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_deserializers.py:231\u001b[0m, in \u001b[0;36mNumpyDeserializer.deserialize\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m content_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/x-npy\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    230\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mload(io\u001b[39m.\u001b[39;49mBytesIO(stream\u001b[39m.\u001b[39;49mread()), allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle)\n\u001b[1;32m    232\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[1;32m    233\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease set the param allow_pickle=True \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m            to deserialize pickle objects in NumpyDeserializer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\u001b[39m.\u001b[39mwith_traceback(ve\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/numpy/lib/npyio.py:418\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 418\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot load file containing pickled data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mwhen allow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(fid, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Please set the param allow_pickle=True                         to deserialize pickle objects in NumpyDeserializer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 955, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 1021, in _stream_output\n",
      "    raise RuntimeError(f\"Failed to run: {process.args}. Process exited with code: {exit_code}\")\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpy952j82r/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 137\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 960, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpy952j82r/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Failed to run: ['docker-compose', '-f', '/tmp/tmpy952j82r/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[Kxqkzxa2pae-algo-1-7fodr exited with code 137\n"
     ]
    }
   ],
   "source": [
    "result = local_predictor.predict(input_data)\n",
    "result\n",
    "# local_predictor.predict(json.dumps(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-Up\n",
    "\n",
    "Remember to clean up any persistent resources that aren't needed anymore to save costs: The most significant of these are real-time prediction endpoints, and this SageMaker Notebook Instance.\n",
    "\n",
    "The SageMaker SDK [Predictor](https://sagemaker.readthedocs.io/en/stable/predictors.html) class provides an interface to clean up real-time prediction endpoints; and SageMaker Notebook Instances can be stopped through the SageMaker Console when you're finished.\n",
    "\n",
    "You might also like to clean up any S3 buckets / content we created, to prevent ongoing storage costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean up any endpoints/etc to release resources"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
