{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# 뉴스 헤드라인 분류하기 (SageMaker 버전)\n",
    "\n",
    "> 이 노트북은 SageMaker Notebook Instance 및 conda_pytorch_p310 및 SageMaker Studio의 `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` 커널에서 잘 작동합니다.\n",
    "\n",
    "이 예제에서는 커스텀 스크립트와 [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) 프레임워크를 사용하여 뉴스 헤드라인 분류기 모델을 훈련할 것입니다.\n",
    "\n",
    "이 \"SageMaker\" 노트북은 Amazon SageMaker 훈련 작업에서 모델을 훈련하고 관리되는 실시간 추론 엔드포인트에 배포하는 방법을 보여줄 것입니다.\n",
    "\n",
    "> ⚠️ 우리는 이미 동반 [\"Headline Classifier Local\" 노트북](Headline%20Classifier%20Local.ipynb)을 실행했다고 가정합니다. 이 노트북은 노트북 자체에서 훈련과 추론을 실행하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## 설치 및 설정\n",
    "\n",
    "로컬 노트북과 마찬가지로 시작하기 전에 위젯 라이브러리가 설정되어 있는지 확인할 것입니다.\n",
    "\n",
    "🟢 하지만 **로컬 노트북과 달리**, **HF Transformers를 설치할 필요가 없다는 점**에 유의하십시오. 실제 훈련과 추론은 컨테이너화된 작업에서 발생하며 이 커널에서는 발생하지 않기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker<3,>2.140 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.237.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (1.35.76)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (0.115.6)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<2.3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (24.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (4.25.5)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (6.1.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (1.0.17)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (4.67.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (2.2.3)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3,>2.140) (0.32.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.76 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker<3,>2.140) (1.35.76)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker<3,>2.140) (0.10.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3,>2.140) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<2.3,>=2.2->sagemaker<3,>2.140) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (2.9.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3,>2.140) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3,>2.140) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3,>2.140) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker<3,>2.140) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker<3,>2.140) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker<3,>2.140) (2024.8.30)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker<3,>2.140) (0.41.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker<3,>2.140) (4.12.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker<3,>2.140) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker<3,>2.140) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker<3,>2.140) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3,>2.140) (1.7.6.9)\n",
      "Collecting dill>=0.3.9 (from pathos->sagemaker<3,>2.140)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pox>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3,>2.140) (0.3.5)\n",
      "Collecting multiprocess>=0.70.17 (from pathos->sagemaker<3,>2.140)\n",
      "  Using cached multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker<3,>2.140) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker<3,>2.140) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (2.18.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.42.0,>=0.40.0->fastapi->sagemaker<3,>2.140) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker<3,>2.140) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker<3,>2.140) (1.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker<3,>2.140) (0.1.2)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
      "Installing collected packages: dill, multiprocess\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.2.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "datasets 3.2.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dill-0.3.9 multiprocess-0.70.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install  \"sagemaker>2.140,<3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c92d98-8e59-4d83-8c18-bd0622c5546a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: jupyterlab in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.2.6)\n",
      "Collecting jupyterlab\n",
      "  Using cached jupyterlab-4.3.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: notebook in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter) (7.2.2)\n",
      "Requirement already satisfied: jupyter-console in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (24.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (75.3.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (2.0.2)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from async-lru>=1.0.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (1.8.8)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.27)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.2.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.2.3)\n",
      "Requirement already satisfied: ptyprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241003)\n",
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install --upgrade jupyter jupyterlab\n",
    "pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "설치가 완료되면 나머지 노트북에서 사용할 라이브러리와 Python 내장 기능을 로드할 것입니다.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)은 로컬 .py 파일로 작업할 때 유용합니다. 각 셀 실행 시 라이브러리를 다시 로드하면 노트북 커널을 다시 시작하지 않고도 로컬로 편집/업데이트된 스크립트를 사용할 수 있기 때문입니다.\n",
    "\n",
    "🟢 이번에는 로컬 노트북에서 필요하지 않았던 일부 **AWS 라이브러리**를 사용할 것입니다:\n",
    "\n",
    "- `boto3`, [Python용 범용 AWS SDK](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "- `sagemaker`, [Amazon SageMaker용 고수준 Python SDK](https://sagemaker.readthedocs.io/en/stable/)\n",
    "\n",
    "이 두 라이브러리는 모두 오픈 소스이며 PyPI와 GitHub에 게시되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/17/24 03:16:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/17/24 03:16:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=393380;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=555697;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General AWS SDK for Python\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "import sagemaker  # High-level Python SDK for Amazon SageMaker\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## 데이터셋 준비 및 업로드하기\n",
    "\n",
    "이 예제는 [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/) 공개 리포지토리에서 **FastAi AG News** 데이터셋을 다운로드합니다. 이 데이터셋에는 뉴스 헤드라인과 해당 주제 클래스가 포함된 테이블이 들어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-nlp/ag_news_csv.tgz to data/ag_news_csv.tgz\n",
      "Done!\n",
      "CPU times: user 11 ms, sys: 39.6 ms, total: 50.6 ms\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "\n",
    "# Push data partitions to separate subfolders, which is useful for local script debugging later\n",
    "os.renames(f\"{local_dir}/test.csv\", f\"{local_dir}/test/test.csv\")\n",
    "os.renames(f\"{local_dir}/train.csv\", f\"{local_dir}/train/train.csv\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "데이터를 다운로드하고 추출한 후 아래와 같이 일부 예제를 탐색할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86110</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Oracle to drop PeopleSoft suit if tender fails</td>\n",
       "      <td>Oracle Corp. notified Delaware's Court of Chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74390</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>NTT DoCoMo, IBM, Intel team to secure mobile d...</td>\n",
       "      <td>With an eye towards making mobile devices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77491</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Election Is Crunch Time for U.S. Secret Service</td>\n",
       "      <td>With just days to go before the U.S. president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27497</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Former Celtic striker Larsson on Barcelona bench</td>\n",
       "      <td>Henrik Larsson was left on the bench by Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47492</th>\n",
       "      <td>World</td>\n",
       "      <td>Four Suicides Linked to Child Porn Probe (AP)</td>\n",
       "      <td>AP - The government will press on with a child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY                                              TITLE  \\\n",
       "86110  Sci/Tech     Oracle to drop PeopleSoft suit if tender fails   \n",
       "74390  Sci/Tech  NTT DoCoMo, IBM, Intel team to secure mobile d...   \n",
       "77491  Sci/Tech    Election Is Crunch Time for U.S. Secret Service   \n",
       "27497    Sports   Former Celtic striker Larsson on Barcelona bench   \n",
       "47492     World      Four Suicides Linked to Child Porn Probe (AP)   \n",
       "\n",
       "                                                 CONTENT  \n",
       "86110  Oracle Corp. notified Delaware's Court of Chan...  \n",
       "74390  With an eye towards making mobile devices and ...  \n",
       "77491  With just days to go before the U.S. president...  \n",
       "27497  Henrik Larsson was left on the bench by Barcel...  \n",
       "47492  AP - The government will press on with a child...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "이 연습에서 우리는 **다음만 사용할 것입니다**:\n",
    "\n",
    "- 뉴스 기사의 **제목**(헤드라인)을 입력으로 사용합니다.\n",
    "- **카테고리**를 예측할 대상 변수로 사용합니다.\n",
    "\n",
    "이 데이터셋에는 아래와 같이 4개의 고르게 분포된 주제 클래스가 포함되어 있습니다.\n",
    "\n",
    "> ℹ️ **'기타'에 대해:** 원시 데이터셋은 1-4의 숫자로 카테고리를 나타내고, 모델은 0부터 시작하는 숫자를 기대하므로, 데이터 준비를 단순하게 유지하고 클래스의 추가적이고 혼란스러운 숫자 표현을 도입하지 않기 위해 사용되지 않은 '기타' 클래스를 삽입했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech    30000\n",
       "Sports      30000\n",
       "World       30000\n",
       "Business    30000\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db84ebf-e768-4d32-ad34-fc627cfe9597",
   "metadata": {},
   "source": [
    "지금까지는 새로운 내용이 없습니다...\n",
    "\n",
    "🟢 SageMaker에서 훈련할 때의 주요 차이점은 **데이터셋을 업로드**해야 한다는 것입니다. [훈련 작업이 액세스할 수 있는 곳](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html)에 업로드해야 합니다.\n",
    "\n",
    "여기서는 [SageMaker 기본 버킷](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-bucket.html)을 사용하여 데이터를 [Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)에 업로드할 것입니다. 원하는 경우 버킷과 폴더 접두사를 사용자 지정할 수 있습니다. 훈련 데이터와 테스트 데이터를 동일한 폴더에 있는 두 파일이 아닌 별도의 S3 폴더로 분리하는 것이 도움이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec896d2-e210-4987-aac5-d21d968816cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/17/24 03:16:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/17/24 03:16:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=900787;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=266354;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=304328;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=657096;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_s3_uri: s3://sagemaker-us-east-1-057716757052/sm101/news/train\n",
      "test_s3_uri: s3://sagemaker-us-east-1-057716757052/sm101/news/test\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "s3_prefix = \"sm101/news\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/train/train.csv\", f\"{s3_prefix}/train/train.csv\")\n",
    "train_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/train\"\n",
    "print(f\"train_s3_uri: {train_s3_uri}\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/test/test.csv\", f\"{s3_prefix}/test/test.csv\")\n",
    "test_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/test\"\n",
    "print(f\"test_s3_uri: {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 훈련 매개변수 정의하기\n",
    "\n",
    "우리는 [Hugging Face Hub](https://huggingface.co/models)에서 (비교적 작은) 사전 훈련된 모델을 미세 조정할 것이며, 낮은 수준의 훈련 루프를 처음부터 작성하는 대신 높은 수준의 [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)를 사용할 것입니다.\n",
    "\n",
    "🟢 우리의 훈련 스크립트는 궁극적으로 이전과 유사한 매개변수를 사용할 것이지만, 이번에는 이러한 매개변수를 **훈련 작업 API를 통해 전달**할 것입니다.\n",
    "\n",
    "여기서는 노트북에서 **JSON 직렬화 가능한 매개변수**를 정의한 다음 이를 사용하여 나중에 `transformers.TrainingArguments`를 빌드할 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21191118-ecc3-4b42-bf84-76882582ce31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'amazon/bort',\n",
       " 'class_names': 'Other,World,Sports,Business,Sci/Tech',\n",
       " 'num_train_epochs': 3,\n",
       " 'per_device_train_batch_size': 32,\n",
       " 'per_device_eval_batch_size': 64,\n",
       " 'warmup_steps': 500}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"model_id\": \"amazon/bort\",  # ID of the pre-trained model to start from\n",
    "    \"class_names\": \",\".join(class_names),  # Comma-separated list of category names\n",
    "    \"num_train_epochs\": 3,  # This time, we'll actually train for a full 3 epochs\n",
    "    \"per_device_train_batch_size\": 32,  # Note this is higher than we could set on local hardware\n",
    "    \"per_device_eval_batch_size\": 64,  # Note this is higher than we could set on local hardware\n",
    "    \"warmup_steps\": 500,  # Higher than we could set with the reduced local training\n",
    "}\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "## 지표 정의하기\n",
    "\n",
    "우리는 훈련된 모델의 품질을 측정하는 방법을 정의하고, 이 정보를 SageMaker에 표시하여 지표 로깅, 자동 모델 튜닝 및 순위표와 같은 기능을 활성화하고자 합니다.\n",
    "\n",
    "🟢 우리는 훈련 코드가 평소와 같이 지표를 출력하도록 하고, [정규 표현식을 사용](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html#define-train-metrics)하여 SageMaker가 작업 로그에서 구조화된 지표를 스크랩하는 방법을 정의할 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935497f0-1b44-450e-a725-8b65509231a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Epoch', 'Regex': \"'epoch': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:Loss', 'Regex': \"'loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:LearningRate', 'Regex': \"'learning_rate': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Loss', 'Regex': \"'eval_loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Accuracy', 'Regex': \"'eval_accuracy': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:F1', 'Regex': \"'eval_f1': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Precision',\n",
       "  'Regex': \"'eval_precision': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Recall', 'Regex': \"'eval_recall': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Runtime', 'Regex': \"'eval_runtime': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:SamplesPerSecond',\n",
       "  'Regex': \"'eval_samples_per_second': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:StepsPerSecond',\n",
       "  'Regex': \"'eval_steps_per_second': ([0-9\\\\.\\\\-e]+)\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"Epoch\", \"Regex\": r\"'epoch': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:Loss\", \"Regex\": r\"'loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:LearningRate\", \"Regex\": r\"'learning_rate': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Loss\", \"Regex\": r\"'eval_loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Accuracy\", \"Regex\": r\"'eval_accuracy': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:F1\", \"Regex\": r\"'eval_f1': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Precision\", \"Regex\": r\"'eval_precision': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Recall\", \"Regex\": r\"'eval_recall': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Runtime\", \"Regex\": r\"'eval_runtime': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:SamplesPerSecond\", \"Regex\": r\"'eval_samples_per_second': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:StepsPerSecond\", \"Regex\": r\"'eval_steps_per_second': ([0-9\\.\\-e]+)\"},\n",
    "]\n",
    "metric_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker에서 모델 훈련 및 검증하기\n",
    "\n",
    "이번에는 노트북 자체와 별도의 인스턴스에서 훈련 프로세스를 실행하기 위해 [SageMaker 훈련 작업](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)을 생성할 것입니다. 이렇게 하면 장기간 유지되는 노트북 환경과 독립적으로 임시 훈련 인프라의 크기를 적절하게 조정할 수 있습니다.\n",
    "\n",
    "🟢 실제 훈련 코드는 노트북에서 **[scripts/train.py](scripts/train.py)**로 분리되었으며, 이 스크립트를 통해 [SageMaker Python SDK를 통한 사전 빌드된 Hugging Face Framework 컨테이너](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html)를 사용하여 모델을 훈련하고 배포할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70294b2-ee08-4c90-a7f7-d88ed52e07cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Amazon SageMaker가 사전 빌드된 컨테이너로 스크립트를 실행하는 방법\n",
    "\n",
    "AWS는 주요 ML 프레임워크에서 프로젝트 구축을 가속화하는 데 도움이 되는 사전 패키지화된 Docker 이미지 세트를 제공합니다: [SageMaker Framework Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html).\n",
    "\n",
    "이러한 컨테이너는 GPU 드라이버, 서빙 스택 구현, 핵심 라이브러리 등과 같은 기본 설정을 처리하므로 우리는 훈련 프로세스와 추론 동작 재정의를 위한 일부 Python 스크립트를 단순히 주입할 수 있습니다. 시작 시 동적으로 설치할 추가 종속성을 지정하기 위해 *requirements.txt* 파일을 제공할 수도 있습니다. 이러한 종속성을 컨테이너 이미지에 빌드할 필요가 없습니다.\n",
    "\n",
    "**결과적으로 우리의 첫 번째 작업은 스크립트(들)와 런타임 간의 인터페이스를 이해하는 것입니다**: 스크립트는 입력 데이터를 어떻게 읽을까요? 매개변수는 어떻게 읽을까요? 결과는 어디에 저장해야 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9095e-38cb-49da-9627-5ae9ff65012b",
   "metadata": {},
   "source": [
    "#### 훈련 중 컨테이너\n",
    "\n",
    "훈련 작업 컨테이너가 시작될 때, **코드와 입력 데이터**는 `/opt/ml` 디렉토리 아래의 **로컬 파일**로 다운로드됩니다. 또한 **훈련된 모델**과 기타 파일 출력을 로컬 파일 시스템에 저장할 것입니다 - 아래와 같이:\n",
    "\n",
    "```\n",
    "    /opt/ml\n",
    "    |-- code\n",
    "    |   `-- <우리의 스크립트(들)>\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <채널 이름>\n",
    "    |           `-- <입력 데이터>\n",
    "    |-- model\n",
    "    |   `-- <모델 파일>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "```\n",
    "\n",
    "##### 입력\n",
    "\n",
    "* `/opt/ml/input/config`는 프로그램 실행 방식을 제어하는 정보를 포함합니다. `hyperparameters.json`은 하이퍼파라미터 이름과 값의 JSON 형식 사전입니다. 이러한 값은 항상 문자열이므로 변환이 필요할 수 있습니다. `resourceConfig.json`은 분산 훈련에 사용되는 네트워크 레이아웃을 설명하는 JSON 형식 파일입니다. scikit-learn은 분산 훈련을 지원하지 않으므로 여기서는 무시할 것입니다.\n",
    "* `/opt/ml/input/data/<채널 이름>/` (파일 모드의 경우)는 해당 채널의 입력 데이터를 포함합니다. 채널은 CreateTrainingJob에 대한 호출을 기반으로 생성되지만 일반적으로 채널이 알고리즘이 기대하는 것과 일치하는 것이 중요합니다. 각 채널의 파일은 S3에서 이 디렉토리로 복사되며, S3 키 구조가 표시하는 트리 구조를 유지합니다.\n",
    "* `/opt/ml/input/data/<채널 이름>_<에포크 번호>` (파이프 모드의 경우)는 주어진 에포크에 대한 파이프입니다. 에포크는 0에서 시작하여 읽을 때마다 1씩 증가합니다. 실행할 수 있는 에포크 수에는 제한이 없지만 다음 에포크를 읽기 전에 각 파이프를 닫아야 합니다.\n",
    "\n",
    "##### 출력\n",
    "\n",
    "* `/opt/ml/model/`은 알고리즘이 생성하는 모델을 작성하는 디렉토리입니다. 모델은 원하는 형식으로 작성할 수 있습니다. 단일 파일이거나 전체 디렉토리 트리일 수 있습니다. SageMaker는 이 디렉토리의 모든 파일을 압축된 tar 아카이브 파일로 패키징합니다. 이 파일은 `DescribeTrainingJob` 결과에서 반환된 S3 위치에서 사용할 수 있습니다.\n",
    "* `/opt/ml/output`은 알고리즘이 작업 실패 이유를 설명하는 `failure` 파일을 작성할 수 있는 디렉토리입니다. 이 파일의 내용은 `DescribeTrainingJob` 결과의 `FailureReason` 필드에 반환됩니다. 성공한 작업의 경우 이 파일을 작성할 이유가 없으므로 무시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f290d-7eb9-4acf-b9d4-5df4a06e3f57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 추가 정보\n",
    "\n",
    "더 많은 정보를 원하시면 다음을 참조하십시오:\n",
    "\n",
    "- Hugging Face를 위한 [SageMaker Python SDK 가이드](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html) 및 [API 문서](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) (PyTorch에 대한 동등한 페이지도 유용할 수 있음).\n",
    "- GitHub의 [AWS Deep Learning Containers 리포지토리](https://github.com/aws/deep-learning-containers)는 기본 컨테이너 이미지를 정의합니다.\n",
    "- 훈련 및 서빙을 위한 프레임워크 코드에 대한 자세한 내용은 오픈 소스 [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit) 및 [SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit)을 참조하십시오. (일부 프레임워크는 이러한 툴킷의 변형을 사용합니다, 예: [sagemaker-pytorch-training-toolkit](https://github.com/aws/sagemaker-pytorch-training-toolkit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25455f6-b3a6-450a-a7be-b5fa8f94f79d",
   "metadata": {},
   "source": [
    "### (선택사항) 스크립트 테스트\n",
    "\n",
    "> ℹ️ **참고:** 이 단계는 선택사항입니다. 이 예제에서는 훈련 스크립트가 이미 구축되고 테스트되었기 때문입니다!\n",
    "\n",
    "작업 스크립트 [train.py](scripts/train.py)가 기본적으로 노트북에서 이전에 수행된 것과 동일한 로직과 프로세스를 따르지만, SageMaker를 위해 수정한 내용을 **테스트**하는 것이 좋을 것입니다.\n",
    "\n",
    "스크립트의 초기 기능 테스트와 디버깅을 위해 매번 전체 SageMaker 훈련 작업을 시작하고 싶지 않을 수 있습니다: 각각의 새로운 작업이 온디맨드 컴퓨팅 리소스를 시작하는 동안 짧은 지연이 발생하기 때문입니다.\n",
    "\n",
    "이 프로세스를 가속화할 수 있는 여러 가지 방법이 있습니다. 일반적으로 [SageMaker Warm Pools](https://docs.aws.amazon.com/sagemaker/latest/dg/train-warm-pools.html)나 [SageMaker Local Mode](https://sagemaker.readthedocs.io/en/stable/overview.html?#local-mode)를 추천하지만, 이는 표준 워크샵 환경에서는 사용할 수 없습니다. 대신, CLI를 통해 훈련 스크립트를 호출하여 **노트북 내에서 훈련 작업을 시뮬레이션**할 수 있습니다.\n",
    "\n",
    "아래 셀의 주석을 해제(`Ctrl`+`/`)하고 실행해볼 수 있습니다 - ⚠️ 하지만 주의하세요: 매우 메모리 집약적이므로, 이전 [Headline Classifier Local 노트북](Headline%20Classifier%20Local.ipynb)의 커널을 먼저 종료하거나 재시작해야 합니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14873a8-9a90-41a7-b5fc-9a88041a577d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class_names_str = \",\".join(class_names)  # Comma-separated list for CLI\n",
    "# !python3 scripts/train.py \\\n",
    "#     --train data/train \\\n",
    "#     --test data/test \\\n",
    "#     --output_data_dir data/local-output \\\n",
    "#     --model_dir data/local-model \\\n",
    "#     --model_id=amazon/bort --class_names={class_names_str} --train_max_steps=20 \\\n",
    "#     --train_batch_size=8 --eval_batch_size=16 --fp16=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d648ba-8214-423e-926d-1417d56e413c",
   "metadata": {},
   "source": [
    "### 작업 생성하기\n",
    "\n",
    "실제 [SageMaker CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)는 SageMaker Python SDK의 [상위 레벨 'Estimator' 클래스](https://sagemaker.readthedocs.io/en/stable/overview.html)가 단순화하는 데 도움이 되는 여러 저수준 세부 사항을 필요로 합니다. 특히:\n",
    "- 정확한 컨테이너 이미지 URI를 지정하는 대신, SDK가 선택된 프레임워크와 버전을 기반으로 이를 찾아줍니다\n",
    "- SDK는 우리의 `scripts` 번들을 자동으로 압축하여 S3에 업로드하고, 훈련 작업이 거기서 로드하도록 구성합니다\n",
    "\n",
    "따라서 먼저, 작업을 구성하고 어떤 인프라(컴퓨팅 인스턴스의 수와 유형)에서 실행되어야 하는지를 지정하는 `estimator` 객체를 생성합니다:\n",
    "\n",
    "> ℹ️ 다른 작업을 대신 실행하는 서비스들처럼, 훈련 작업은 S3의 입력 훈련 데이터와 같은 리소스에 접근할 수 있도록 [IAM 역할](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)을 가정합니다. SageMaker 노트북 자체가 이미 가정된 역할로 실행되고 있으므로, 단순화를 위해 훈련 작업 역할을 노트북 역할과 동일하게 설정할 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f6dbe0-6c13-4199-b219-5fe4e4543d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.estimator import HuggingFace as HuggingFaceEstimator\n",
    "\n",
    "nb_role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = HuggingFaceEstimator(\n",
    "    transformers_version=\"4.26\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "\n",
    "    source_dir=\"scripts\",  # Local folder where fine-tuning script is stored\n",
    "    entry_point=\"train.py\",  # Actual script the training job should run\n",
    "\n",
    "    base_job_name=\"news-classifier\",  # Prefix for the training job name (timestamp will be added)\n",
    "    instance_count=1,  # Number of instances train on (need to prepare your script for using >1!)\n",
    "    # instance_type=\"ml.p3.2xlarge\",  # Type of compute instance to use: p* and g* include GPUs\n",
    "    instance_type=\"ml.g5.4xlarge\",  # Type of compute instance to use: p* and g* include GPUs\n",
    "    role=nb_role,  # IAM role the job will use to access AWS resources (e.g. data on S3)\n",
    "\n",
    "    hyperparameters=hyperparameters,   # Training job parameters, as we set up earlier\n",
    "    metric_definitions=metric_definitions,  # RegEx to extract metric data from training job logs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c804ca-7678-4277-9f74-f3851d7efa5a",
   "metadata": {},
   "source": [
    "구성이 완료되면, 입력 데이터 위치를 지정하고 `estimator.fit()`을 실행하여 실제 훈련 작업을 시작할 수 있습니다.\n",
    "\n",
    "데이터 입력 \"채널\"의 수, 이름 및 유형은 [사용자가 결정](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html#sagemaker-CreateTrainingJob-request-InputDataConfig)할 수 있습니다: 단지 노트북이 스크립트에서 기대하는 것과 동일한 채널을 구성하도록 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/17/24 03:16:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/17/24 03:16:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=712988;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=986509;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=287746;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=334945;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         news-classifier-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-12-17-03-16-30-011                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=421460;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=347726;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         news-classifier-\u001b[1;36m2024\u001b[0m-12-17-03-16-30-011                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 03:16:30 Starting - Starting the training job\n",
      "2024-12-17 03:16:30 Pending - Training job waiting for capacity......\n",
      "2024-12-17 03:17:07 Pending - Preparing the instances for training...\n",
      "2024-12-17 03:17:49 Downloading - Downloading the training image.....................\n",
      "2024-12-17 03:21:11 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:41,794 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:41,815 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:41,830 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:41,832 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:42,967 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:43,022 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:43,076 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:43,099 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"class_names\": \"Other,World,Sports,Business,Sci/Tech\",\n",
      "        \"model_id\": \"amazon/bort\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"per_device_eval_batch_size\": 64,\n",
      "        \"per_device_train_batch_size\": 32,\n",
      "        \"warmup_steps\": 500\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"news-classifier-2024-12-17-03-16-30-011\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/news-classifier-2024-12-17-03-16-30-011/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/news-classifier-2024-12-17-03-16-30-011/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"news-classifier-2024-12-17-03-16-30-011\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/news-classifier-2024-12-17-03-16-30-011/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--class_names\",\"Other,World,Sports,Business,Sci/Tech\",\"--model_id\",\"amazon/bort\",\"--num_train_epochs\",\"3\",\"--per_device_eval_batch_size\",\"64\",\"--per_device_train_batch_size\",\"32\",\"--warmup_steps\",\"500\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_NAMES=Other,World,Sports,Business,Sci/Tech\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=amazon/bort\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=500\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --class_names Other,World,Sports,Business,Sci/Tech --model_id amazon/bort --num_train_epochs 3 --per_device_eval_batch_size 64 --per_device_train_batch_size 32 --warmup_steps 500\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:43,135 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:51,243 - __main__ - INFO - Loaded train_dataset length is: 120000\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\u001b[0m\n",
      "\u001b[34m2024-12-17 03:21:51,449 - __main__ - INFO - Loaded test_dataset length is: 7600\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 120000\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 120000\u001b[0m\n",
      "\u001b[34mNum Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mNum Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.551 algo-1:67 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.647 algo-1:67 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.648 algo-1:67 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.648 algo-1:67 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.649 algo-1:67 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-12-17 03:21:52.649 algo-1:67 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m{'loss': 1.3396, 'learning_rate': 5e-05, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8085, 'learning_rate': 4.7674418604651164e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.622, 'learning_rate': 4.5348837209302326e-05, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5342, 'learning_rate': 4.302325581395349e-05, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5222, 'learning_rate': 4.0697674418604655e-05, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4979, 'learning_rate': 3.837209302325582e-05, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4733, 'learning_rate': 3.604651162790698e-05, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4458867013454437, 'eval_accuracy': 0.848421052631579, 'eval_f1': 0.848421052631579, 'eval_precision': 0.848421052631579, 'eval_recall': 0.848421052631579, 'eval_runtime': 0.8185, 'eval_samples_per_second': 9285.259, 'eval_steps_per_second': 145.388, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3922, 'learning_rate': 3.372093023255814e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.347, 'learning_rate': 3.13953488372093e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3399, 'learning_rate': 2.9069767441860467e-05, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3332, 'learning_rate': 2.674418604651163e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3267, 'learning_rate': 2.441860465116279e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.332, 'learning_rate': 2.2097674418604654e-05, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3378, 'learning_rate': 1.9772093023255812e-05, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3379, 'learning_rate': 1.7446511627906977e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4206923246383667, 'eval_accuracy': 0.8603947368421052, 'eval_f1': 0.8603947368421052, 'eval_precision': 0.8603947368421052, 'eval_recall': 0.8603947368421052, 'eval_runtime': 0.8174, 'eval_samples_per_second': 9297.397, 'eval_steps_per_second': 145.578, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.229, 'learning_rate': 1.5125581395348836e-05, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2281, 'learning_rate': 1.2800000000000001e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.23, 'learning_rate': 1.0474418604651164e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2378, 'learning_rate': 8.148837209302326e-06, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2239, 'learning_rate': 5.827906976744187e-06, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2324, 'learning_rate': 3.502325581395349e-06, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2282, 'learning_rate': 1.1767441860465117e-06, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.440890908241272, 'eval_accuracy': 0.8644736842105263, 'eval_f1': 0.8644736842105263, 'eval_precision': 0.8644736842105263, 'eval_recall': 0.8644736842105263, 'eval_runtime': 0.8169, 'eval_samples_per_second': 9302.899, 'eval_steps_per_second': 145.664, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.8644736842105263).\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.8644736842105263).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 346.6737, 'train_samples_per_second': 1038.441, 'train_steps_per_second': 32.451, 'train_loss': 0.41131197713216144, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.440890908241272, 'eval_accuracy': 0.8644736842105263, 'eval_f1': 0.8644736842105263, 'eval_precision': 0.8644736842105263, 'eval_recall': 0.8644736842105263, 'eval_runtime': 0.8156, 'eval_samples_per_second': 9318.864, 'eval_steps_per_second': 145.914, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m2024-12-17 03:27:41,374 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-12-17 03:27:41,374 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-12-17 03:27:41,374 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-12-17 03:28:00 Uploading - Uploading generated training model\n",
      "2024-12-17 03:28:00 Completed - Training job completed\n",
      "Training seconds: 622\n",
      "Billable seconds: 622\n",
      "CPU times: user 1.17 s, sys: 116 ms, total: 1.28 s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(\n",
    "    {\n",
    "        \"train\": train_s3_uri,\n",
    "        \"test\": test_s3_uri,\n",
    "    },\n",
    "    wait=True,  # Wait for the training to complete (default=True)\n",
    "    logs=True,  # Stream training job logs to the notebook (default=True, requires wait=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c940a-77cc-472e-8263-fe2a0c236f9b",
   "metadata": {},
   "source": [
    "> ⏰ 이 훈련 작업은 완료하는 데 약 10분이 소요되지만, '로컬' 모델보다 상당히 높은 정확도에 도달할 것입니다\n",
    "\n",
    "CPU만 있는 작은 노트북 대신 GPU 가속 인스턴스에서 실행되기 때문에, 훈련 자체는 이전 '로컬' 예제보다 훨씬 더 빠를 것입니다. 하지만 작업이 인프라를 프로비저닝하고 시작하는 데 몇 분 정도 걸릴 수 있습니다.\n",
    "\n",
    "현재 및 과거 작업의 상태는 [AWS Console for Amazon SageMaker](https://console.aws.amazon.com/sagemaker/home?#/jobs)의 *Training jobs* 페이지와 SageMaker Studio의 **Experiments** UI(왼쪽 사이드바의 🏠 **Home** 버튼에서)에서도 확인할 수 있습니다.\n",
    "\n",
    "🟢 대기하고 로그를 스트리밍하는 기본 동작이 로컬과 비슷한 경험을 제공하지만, 훈련 작업은 노트북에 의존하지 않습니다:\n",
    "- 노트북의 연결이 끊어지거나 종료되어도 훈련 작업은 계속됩니다\n",
    "- `wait=False`를 설정하면 노트북에서 여러 훈련 작업을 병렬로 시작할 수 있습니다\n",
    "- 재시작된 노트북을 이전 훈련 작업에 연결해야 할 경우, 아래와 같이 훈련 작업 이름으로 `.attach()`할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6156d24-b630-4df3-a912-18cf1ed002f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = HuggingFaceEstimator.attach(\"news-hf-2020-01-01-12-00-00-000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511626-84a6-4579-9a77-39d0fc048cc9",
   "metadata": {},
   "source": [
    "훈련 작업이 완료되면, 컨테이너의 모델 출력 폴더의 내용이 자동으로 S3에 아카이브됩니다.\n",
    "\n",
    "아래와 같이 이 파일을 참조할 수 있으며, 비슷한 tar 압축 형식으로 준비하여 SageMaker 외부에서 훈련된 모델을 배포용으로 가져올 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c490cab6-7ae5-450d-b7ae-ff8156e5817d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/news-classifier-2024-12-17-03-16-30-011/output/model.tar.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150a348-e0c3-40c7-9d5e-14c8c6986033",
   "metadata": {},
   "source": [
    "## 모델을 추론에 사용하기\n",
    "\n",
    "모델 훈련이 완료되면, 새로운 데이터에 대한 추론을 수행할 준비가 된 것입니다.\n",
    "SageMaker는 [온디맨드 추론을 위한 모델 배포](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) 또는 [배치 추론 작업 실행](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)을 위한 여러 완전 관리형 옵션을 제공합니다.\n",
    "\n",
    "> ℹ️ **기억하세요:** 사용 사례에 맞는 적절한 추론 옵션을 선택하세요 - 단순히 배치 데이터를 처리하고 싶다면 실시간 엔드포인트를 배포할 필요가 없습니다!\n",
    ">\n",
    "> 지금까지 사용해온 동일한 상위 레벨 SageMaker Python SDK를 통해 배치 추론을 실행하는 방법에 대한 자세한 내용은 [SageMaker Batch Transform 사용하기](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)를 참조하세요.\n",
    "\n",
    "이 예제에서는 모델을 [실시간 추론 엔드포인트](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)에 배포할 것입니다. 이를 통해 온디맨드로 헤드라인을 분류할 수 있습니다.\n",
    "\n",
    "다시 한 번 엔드포인트를 실행할 인프라 유형을 지정할 것입니다. 따라서 시작하는 데 몇 분이 걸릴 것입니다. 이 테스트 엔드포인트는 매우 적은 트래픽을 처리할 것이므로, 훈련 때와는 **다른 유형**의 인스턴스를 사용할 수 있습니다 - 더 작고 저렴한 인프라를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795f1525-b0f1-449a-9c17-e3b587e77a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/17/24 03:28:23] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: news-classifier-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-12-17-03-28-23-804      <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/17/24 03:28:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: news-classifier-\u001b[1;36m2024\u001b[0m-12-17-03-28-23-804      \u001b]8;id=701747;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=471083;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/17/24 03:28:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         news-classifier-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-12-17-03-28-23-804                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/17/24 03:28:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=920861;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=481125;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         news-classifier-\u001b[1;36m2024\u001b[0m-12-17-03-28-23-804                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name news-classifier-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-12-17-03-28-23-804    <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name news-classifier-\u001b[1;36m2024\u001b[0m-12-17-03-28-23-804    \u001b]8;id=276675;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=52367;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322a7f0-e2c1-45ec-9a96-eb64036c8384",
   "metadata": {},
   "source": [
    "배포 후에는 [AWS Console for Amazon SageMaker](https://console.aws.amazon.com/sagemaker/home?#/endpoints)의 *Endpoints* 페이지와 SageMaker Studio UI의 **Deployments > Endpoints** 섹션(왼쪽 사이드바의 🏠 **Home** 버튼에서)에서 엔드포인트를 찾을 수 있습니다.\n",
    "\n",
    "훈련 작업과 마찬가지로, 엔드포인트는 노트북 자체와 분리되어 있습니다. 다음과 같이 이전에 배포된 엔드포인트에 노트북을 연결할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1371515a-ed8a-41a2-87f8-3fdf63dcfb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.huggingface import HuggingFacePredictor\n",
    "# predictor = HuggingFacePredictor(\"news-classifier-2023-03-24-13-31-09-895\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "## 이제 모델이 RESTful API로 프로덕션 환경에 배포되었습니다!\n",
    "\n",
    "[Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html)는 여기서 모델을 메모리에 로드하지 않고, 대신 배포된 엔드포인트에 대한 HTTPS API 호출을 래핑합니다.\n",
    "\n",
    "여기서는 Hugging Face 프레임워크에서 제공하는 기본 `application/json` 직렬화를 사용하고 있지만, 다른 프레임워크들은 서로 다른 기본 형식을 가지고 있으며, 사용자 지정 [serializers](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html)와 [deserializers](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html)(클라이언트/`predictor` 측)와 사용자 지정 [`input_fn`과 `output_fn`](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#process-model-input)(엔드포인트 컨테이너 측)을 사용하여 원하는 거의 모든 요청 또는 응답 형식을 설정할 수 있습니다: 서빙 스택을 처음부터 직접 작성할 필요가 없습니다.\n",
    "\n",
    "요청 직렬화/역직렬화 및 처리는 [HuggingFacePredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-predictor)와 미리 빌드된 추론 컨테이너에 의해 처리되므로, 노트북에서 배포된 모델을 호출하는 것은 로컬 인메모리 모델을 호출하는 것만큼 쉽습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919d5103664d456d99f634474fd7785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='The markets were bullish after news of the merger', continuous_update=False,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    return predictor.predict({\"inputs\":[text]})[0]\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "Alternatively (if e.g. you're struggling with the UI widget library), you can call the endpoint direct from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Business', 'score': 0.9933713674545288}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdcac-2f7c-43c6-8af0-a595960c9d07",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "SageMaker 작업(훈련, 처리, 배치 추론 등)은 실행되는 동안만 온디맨드 컴퓨팅을 사용하지만, 배포된 실시간 추론 엔드포인트는 종료할 때까지 계속해서 리소스를 소비합니다.\n",
    "\n",
    "실험이 끝나면, 불필요한 비용을 피하기 위해 더 이상 필요하지 않은 엔드포인트를 삭제하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b26b2cec-d728-4b90-ba01-98b5bd5c0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## 검토\n",
    "\n",
    "이 노트북에서는 Amazon SageMaker에서 Hugging Face transformers를 사용하여 텍스트 분류 모델을 훈련하고 배포하는 방법을 보여주었습니다.\n",
    "\n",
    "[Headline Classifier Local 노트북](Headline%20Classifier%20Local.ipynb)과 비교했을 때 이 접근 방식의 장점은 다음과 같습니다:\n",
    "- 훈련 작업 기간 **동안만** 전문 컴퓨팅 리소스(예: 고성능 또는 GPU 가속 인스턴스)를 자동으로 프로비저닝할 수 있습니다: 리소스가 활용도가 낮은 상태로 방치되지 않으면서 훈련에서 좋은 성능을 얻을 수 있습니다\n",
    "- 사용자가 무엇이 효과가 있었고 무엇이 효과가 없었는지 기록해야 하는 로컬 노트북 실험과 달리, 훈련 작업의 이력(매개변수, 메트릭, 출력 등 포함)이 자동으로 추적됩니다\n",
    "- 훈련된 모델을 SDK 호출 한 번으로 안전한 프로덕션 준비된 웹 엔드포인트에 배포할 수 있습니다: 동작을 깊이 사용자 지정하고 싶지 않다면 컨테이너나 웹 애플리케이션 패키징이 필요 없습니다\n",
    "\n",
    "로컬 노트북과 이 SageMaker 버전, 그리고 동봉된 [scripts/train.py](scripts/train.py) 스크립트 파일을 비교함으로써, 자신의 또는 오픈 소스 노트북 내 ML 워크플로우를 SageMaker \"스크립트 모드\" 훈련 작업으로 마이그레이션하는 방법에 대한 아이디어를 얻을 수 있습니다.\n",
    "\n",
    "이 워크샵의 다음 \"마이그레이션 챌린지\" 연습에서는 다른 \"로컬\" 노트북에 대해 이 프로세스를 직접 반복해볼 것입니다.\n",
    "\n",
    "또한 SageMaker 작업을 파이프라인으로 연결하고 CI/CD로 워크플로우를 자동화하는 등의 추가 단계를 보여주는 [aws-samples/amazon-sagemaker-from-idea-to-production](https://github.com/aws-samples/amazon-sagemaker-from-idea-to-production)에도 관심이 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e131-4b71-4acc-9b24-0721ebef69dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
